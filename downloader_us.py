# -*- coding: utf-8 -*-
import os, time, random, requests, json
import pandas as pd
import yfinance as yf
from datetime import datetime
from io import StringIO
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
from pathlib import Path

# ========== æ ¸å¿ƒåƒæ•¸è¨­å®š ==========
MARKET_CODE = "us-share"
DATA_SUBDIR = "dayK"
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "data", MARKET_CODE, DATA_SUBDIR)
# ğŸš€ çµ±ä¸€å¿«å–çµæ§‹
LIST_DIR = os.path.join(BASE_DIR, "data", MARKET_CODE, "lists")
CACHE_LIST_PATH = os.path.join(LIST_DIR, "us_stock_list_cache.json")

MAX_WORKERS = 5 
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(LIST_DIR, exist_ok=True)

def log(msg: str):
    print(f"{pd.Timestamp.now():%H:%M:%S}: {msg}")

def classify_security(name: str, is_etf: bool) -> str:
    if is_etf: return "Exclude"
    n_upper = str(name).upper()
    exclude_keywords = ["WARRANT", "RIGHTS", "UNIT", "PREFERRED", "DEPOSITARY", "ADR", "FOREIGN", "DEBENTURE"]
    if any(kw in n_upper for kw in exclude_keywords): return "Exclude"
    return "Common Stock"

def get_full_stock_list():
    """
    ç²å–ç¾è‚¡æ¸…å–®ï¼Œå¢åŠ  3000 æª”é˜²å‘†é–€æª»
    """
    threshold = 3000 # ç¾è‚¡æ™®é€šè‚¡é€šå¸¸åœ¨ 4000-6000 æª”ä¹‹é–“
    
    # 1. æª¢æŸ¥ä»Šæ—¥å¿«å–
    if os.path.exists(CACHE_LIST_PATH):
        try:
            file_mtime = os.path.getmtime(CACHE_LIST_PATH)
            if datetime.fromtimestamp(file_mtime).date() == datetime.now().date():
                with open(CACHE_LIST_PATH, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    if len(data) >= threshold:
                        log(f"ğŸ“¦ è¼‰å…¥ä»Šæ—¥ç¾è‚¡å¿«å– ({len(data)} æª”)...")
                        return data
        except: pass

    log("ğŸ“¡ é–‹å§‹å¾å®˜ç¶²ç²å–ç¾è‚¡æ™®é€šè‚¡æ¸…å–®...")
    all_rows = []

    # å˜—è©¦ç²å–æ¸…å–® (NASDAQ & NYSE)
    for site in ["nasdaqlisted.txt", "otherlisted.txt"]:
        try:
            url = f"https://www.nasdaqtrader.com/dynamic/symdir/{site}"
            r = requests.get(url, timeout=15)
            df = pd.read_csv(StringIO(r.text), sep="|")
            df = df[df["Test Issue"] == "N"]
            
            # æ¬„ä½åç¨±æ ¡æ­£ (Nasdaq è·Ÿ Other æ¬„ä½åç•¥æœ‰ä¸åŒ)
            sym_col = "Symbol" if site == "nasdaqlisted.txt" else "NASDAQ Symbol"
            
            df["Category"] = df.apply(lambda row: classify_security(row["Security Name"], row["ETF"] == "Y"), axis=1)
            # éæ¿¾æ™®é€šè‚¡
            valid_df = df[df["Category"] == "Common Stock"]
            
            for _, row in valid_df.iterrows():
                ticker = str(row[sym_col]).strip().replace('$', '-')
                name = str(row['Security Name']).strip()
                all_rows.append(f"{ticker}&{name}")
            time.sleep(1) # å…©æ¬¡è«‹æ±‚é–“ç¨å¾®åœé “
        except Exception as e:
            log(f"âš ï¸ {site} ç²å–å¤±æ•—: {e}")

    final_list = list(set(all_rows))
    
    # æ•¸é‡é–€æª»æª¢æŸ¥
    if len(final_list) >= threshold:
        with open(CACHE_LIST_PATH, "w", encoding="utf-8") as f:
            json.dump(final_list, f, ensure_ascii=False)
        log(f"âœ… ç¾è‚¡æ¸…å–®æ›´æ–°å®Œæˆï¼Œå…± {len(final_list)} æª”ã€‚")
        return final_list
    elif os.path.exists(CACHE_LIST_PATH):
        log("âš ï¸ ç²å–æ•¸é‡ä¸è¶³ï¼Œä½¿ç”¨æ­·å²å¿«å–å‚™æ´...")
        with open(CACHE_LIST_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    
    return final_list

def download_stock_data(item):
    """
    å–®æª”ä¸‹è¼‰ï¼šå…·å‚™éš¨æ©Ÿäº‚æ•¸èˆ‡é‡è©¦æ©Ÿåˆ¶
    """
    try:
        yf_tkr, name = item.split('&', 1)
        safe_name = "".join([c for c in name if c.isalnum() or c in (' ', '_', '-')]).strip()
        out_path = os.path.join(DATA_DIR, f"{yf_tkr}_{safe_name}.csv")
        
        if os.path.exists(out_path) and os.path.getsize(out_path) > 1000:
            return {"status": "exists", "tkr": yf_tkr}

        # ğŸš€ ä¸‹è¼‰å‰éš¨æ©Ÿç­‰å¾… (Jitter)
        time.sleep(random.uniform(0.5, 1.5))
        tk = yf.Ticker(yf_tkr)
        
        for attempt in range(2):
            try:
                hist = tk.history(period="2y", timeout=20)
                if hist is not None and not hist.empty:
                    hist.reset_index(inplace=True)
                    hist.columns = [c.lower() for c in hist.columns]
                    # ç§»é™¤æ™‚å€
                    if 'date' in hist.columns:
                        hist['date'] = pd.to_datetime(hist['date'], utc=True).dt.tz_localize(None)
                    hist.to_csv(out_path, index=False, encoding='utf-8-sig')
                    return {"status": "success", "tkr": yf_tkr}
            except Exception as e:
                if "Rate limited" in str(e):
                    time.sleep(random.uniform(30, 60)) # è¢«é™æµæ™‚åœæ›´ä¹…
            
            # å¤±æ•—å¾Œéš¨æ©Ÿç­‰å¾…å†é‡è©¦
            time.sleep(random.uniform(2, 5))

        return {"status": "empty", "tkr": yf_tkr}
    except:
        return {"status": "error"}

def main():
    items = get_full_stock_list()
    if not items: return log("âŒ ç„¡æ³•å–å¾—æ¸…å–®ã€‚")

    log(f"ğŸš€ é–‹å§‹ç¾è‚¡ä¸‹è¼‰ä»»å‹™ (å…± {len(items)} æª”)")
    stats = {"success": 0, "exists": 0, "empty": 0, "error": 0}
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(download_stock_data, it): it for it in items}
        pbar = tqdm(total=len(items), desc="ç¾è‚¡ä¸‹è¼‰é€²åº¦")
        for future in as_completed(futures):
            res = future.result()
            stats[res.get("status", "error")] += 1
            pbar.update(1)
        pbar.close()
    
    log(f"ğŸ“Š å ±å‘Š: æˆåŠŸ={stats['success']}, å·²å­˜åœ¨={stats['exists']}, å¤±æ•—={stats['error']}")

if __name__ == "__main__":
    main()
